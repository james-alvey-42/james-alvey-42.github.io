I"_<p>This post is based on a presentation given at King’s College London for a session aimed at PhD students who use computational tools in their research. The aim was to agree on a good development strategy in terms of performance, version control and testing. You can find the <i class="fa fa-envelope-o"></i> PDF here.</p>

<h2 id="numba-python-library">Numba Python Library</h2>

<p>The main reference for this page is just the <a href="https://numba.pydata.org/">Numba Website</a> which has links to all the reference material. We present just a set of minimal examples that can be implemented to find easy speed increases in Python code. Most of what follows is understanding how to use some very simple decorators on your already written functions. These include;</p>

<ul>
  <li><code class="highlighter-rouge">@jit</code> “Just In Time” compilation decorator which optimizes the calculations especially if type information is given.</li>
  <li><code class="highlighter-rouge">@vectorize</code> Many functions in numpy are “universal” in the sense that they can apply element-wise operations to arrays, this is a way of generating your own.</li>
</ul>

<h3 id="nopython-mode"><code class="highlighter-rouge">nopython</code> Mode</h3>

<p>The Numba <code class="highlighter-rouge">@jit</code> decorator fundamentally operates in two compilation modes, <code class="highlighter-rouge">nopython</code> mode and <code class="highlighter-rouge">object</code> mode. The behaviour of the <code class="highlighter-rouge">nopython</code> compilation mode is to essentially compile the decorated function so that it will run entirely without the involvement of the Python interpreter. This is the recommended and best-practice way to use the Numba jit decorator as it leads to the best performance.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="o">@</span><span class="n">jit</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">go_fast</span><span class="p">(</span><span class="n">a</span><span class="p">):</span> <span class="c1"># Function is compiled and runs in machine code
</span>    <span class="n">trace</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">trace</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">trace</span>

<span class="c1"># DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!
</span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">go_fast</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Elapsed (with compilation) = </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>

<span class="c1"># NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE
</span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">go_fast</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Elapsed (after compilation) = </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;</span> <span class="n">Elapsed</span> <span class="p">(</span><span class="k">with</span> <span class="n">compilation</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.1720</span>
<span class="o">&gt;&gt;</span> <span class="n">Elapsed</span> <span class="p">(</span><span class="n">after</span> <span class="n">compilation</span><span class="p">)</span> <span class="o">=</span> <span class="mf">4.220e-05</span></code></pre></figure>

<h3 id="how-does-numba-work">How does Numba Work?</h3>

<p>Numba reads the Python bytecode for a decorated function and combines this with information about the types of the input arguments to the function. It analyzes and optimizes your code, and finally uses the LLVM compiler library to generate a machine code version of your function, tailored to your CPU capabilities. There is also support for Nvidia CUDA GPUs. This compiled version is then used every time your function is called.</p>

<h3 id="other-decorators">Other Decorators</h3>

<ul>
  <li><code class="highlighter-rouge">@njit</code> - this is an alias for <code class="highlighter-rouge">@jit(nopython=True)</code> as it is so commonly used!</li>
  <li><code class="highlighter-rouge">@vectorize</code> - produces NumPy ufunc s (with all the ufunc methods supported).</li>
  <li><code class="highlighter-rouge">@guvectorize</code> - produces NumPy generalized ufunc s. Docs are here.</li>
  <li><code class="highlighter-rouge">@stencil</code> - declare a function as a kernel for a stencil like operation.</li>
  <li><code class="highlighter-rouge">@jitclass</code> - for jit aware classes.</li>
  <li><code class="highlighter-rouge">@cfunc</code> - declare a function for use as a native call back (to be called from C/C++ etc).</li>
  <li><code class="highlighter-rouge">@overload</code> - register your own implementation of a function for use in <code class="highlighter-rouge">nopython</code> mode, e.g. <code class="highlighter-rouge">@overload(scipy.special.j0)</code>.</li>
</ul>

<h3 id="extra-options">Extra Options</h3>

<ul>
  <li><code class="highlighter-rouge">paralell = True</code> - enables the automatic parallelization of the function.</li>
  <li><code class="highlighter-rouge">fastmath = True</code> - enables fast-math behaviour for the function.</li>
</ul>

<h3 id="compiling-python-code-with-jit">Compiling Python code with <code class="highlighter-rouge">@jit</code></h3>

<p>The recommended way to use the <code class="highlighter-rouge">@jit</code> decorator is to let Numba decide when and how to optimize. For example,</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span>

<span class="o">@</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span></code></pre></figure>

<p>You can also tell Numba the function signature you are expecting. The function <code class="highlighter-rouge">f(x, y)</code> would now look like:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span><span class="p">,</span> <span class="n">int32</span>

<span class="o">@</span><span class="n">jit</span><span class="p">(</span><span class="n">int32</span><span class="p">(</span><span class="n">int32</span><span class="p">,</span> <span class="n">int32</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

<span class="c1"># The higher order bits get discarded so can lead
# to counterintuitive results
</span><span class="n">f</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">31</span><span class="p">,</span> <span class="mi">2</span><span class="o">**</span><span class="mi">31</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;</span> <span class="mi">1</span></code></pre></figure>

<p><code class="highlighter-rouge">int32(int32, int32)</code> is the function’s signature. In this case, the corresponding specialization will be compiled by the <code class="highlighter-rouge">@jit</code> decorator, and no other specialization will be allowed. This is useful if you want fine-grained control over types chosen by the compiler (for example, to use single-precision floats).</p>

<h3 id="compilation-options">Compilation Options</h3>

<ol>
  <li><code class="highlighter-rouge">nopython</code> Numba has two compilation modes: nopython mode and object mode. The former produces much faster code, but has limitations that can force Numba to fall back to the latter. To prevent Numba from falling back, and instead raise an error, pass <code class="highlighter-rouge">nopython=True</code>.</li>
  <li><code class="highlighter-rouge">cache</code> To avoid compilation times each time you invoke a Python program, you can instruct Numba to write the result of function compilation into a file-based cache. This is done by passing <code class="highlighter-rouge">cache=True</code>.</li>
  <li><code class="highlighter-rouge">parallel</code> Enables automatic parallelization (and related optimizations) for those operations in the function known to have parallel semantics. This feature is enabled by passing <code class="highlighter-rouge">parallel=True</code> and must be used in conjunction with <code class="highlighter-rouge">nopython=True</code>.</li>
</ol>

<h3 id="creating-numpy-universal-functions">Creating NumPy Universal Functions</h3>

<p>Numba’s vectorize allows Python functions taking scalar input arguments to be used as NumPy ufuncs. Creating a traditional NumPy ufunc is not the most straightforward process and involves writing some C code. Numba makes this easy. Using the <code class="highlighter-rouge">vectorize()</code> decorator, Numba can compile a pure Python function into a ufunc that operates over NumPy arrays as fast as traditional ufuncs written in C.</p>

<p>Using <code class="highlighter-rouge">vectorize()</code>, you write your function as operating over input scalars, rather than arrays. Numba will generate the surrounding loop (or kernel) allowing efficient iteration over the actual inputs.</p>

<p>The <code class="highlighter-rouge">vectorize()</code> decorator has two modes of operation:</p>

<ul>
  <li>Eager, or decoration-time, compilation: If you pass one or more type signatures to the decorator, you will be building a Numpy universal function (ufunc). The rest of this subsection describes building ufuncs using decoration-time compilation.</li>
  <li>Lazy, or call-time, compilation: When not given any signatures, the decorator will give you a Numba dynamic universal function (DUFunc) that dynamically compiles a new kernel when called with a previously unsupported input type.</li>
</ul>

<p>As described above, if you pass a list of signatures to the vectorize() decorator, your function will be compiled into a Numpy ufunc. In the basic case, only one signature will be passed:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">vectorize</span><span class="p">,</span> <span class="n">float64</span>

<span class="o">@</span><span class="n">vectorize</span><span class="p">([</span><span class="n">float64</span><span class="p">(</span><span class="n">float64</span><span class="p">,</span> <span class="n">float64</span><span class="p">)])</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span></code></pre></figure>

<p>If you pass several signatures, beware that you have to pass most specific signatures before least specific ones (e.g., single-precision floats before double-precision floats), otherwise type-based dispatching will not work as expected:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">vectorize</span><span class="p">,</span> <span class="n">int32</span><span class="p">,</span> <span class="n">int64</span><span class="p">,</span> <span class="n">float32</span><span class="p">,</span> <span class="n">float64</span>
<span class="o">@</span><span class="n">vectorize</span><span class="p">([</span><span class="n">int32</span><span class="p">(</span><span class="n">int32</span><span class="p">,</span> <span class="n">int32</span><span class="p">),</span>
            <span class="n">int64</span><span class="p">(</span><span class="n">int64</span><span class="p">,</span> <span class="n">int64</span><span class="p">),</span>
            <span class="n">float32</span><span class="p">(</span><span class="n">float32</span><span class="p">,</span> <span class="n">float32</span><span class="p">),</span>
            <span class="n">float64</span><span class="p">(</span><span class="n">float64</span><span class="p">,</span> <span class="n">float64</span><span class="p">)])</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span></code></pre></figure>

<p>To see a simple example consider the following code:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">not_vectorized</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="s">r"""
    Here, x is an array that we will perform an element wise operation on.
    This is the case where the operation is not vectorized.

    Parameters
    ----------
    x : float
            input

    Returns
    -------
    y : float
            output
    """</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="o">@</span><span class="n">vectorize</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">vectorized</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="s">r"""
    Here, x is an array that we will perform an element wise operation on. 
    This is the case where the operation is vectorized.

    Parameters
    ----------
    x : float or array
            input

    Returns
    -------
    y : float or array
            output
    """</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">y</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span> <span class="n">gives</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>

<span class="o">&gt;&gt;</span> <span class="n">Now</span> <span class="n">we</span> <span class="k">try</span> <span class="k">with</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span>  <span class="mi">0</span>  <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="n">Calling</span> <span class="n">not_vectorized</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="n">gives</span> <span class="n">the</span> <span class="n">following</span> <span class="n">error</span>
<span class="o">&gt;&gt;</span> <span class="n">ERROR</span><span class="p">:</span> <span class="n">The</span> <span class="n">truth</span> <span class="n">value</span> <span class="n">of</span> <span class="n">an</span> <span class="n">array</span> <span class="k">with</span> <span class="n">more</span> <span class="n">than</span> <span class="n">one</span> <span class="n">element</span> <span class="ow">is</span> <span class="n">ambiguous</span><span class="o">.</span> <span class="n">Use</span> <span class="n">a</span><span class="o">.</span><span class="nb">any</span><span class="p">()</span> <span class="ow">or</span> <span class="n">a</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span>
<span class="o">&gt;&gt;</span> <span class="n">We</span> <span class="n">see</span> <span class="n">that</span> <span class="n">the</span> <span class="n">operation</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">work</span>
<span class="o">&gt;&gt;</span> <span class="n">Now</span> <span class="n">we</span> <span class="k">try</span> <span class="n">the</span> <span class="n">same</span> <span class="k">with</span> <span class="n">the</span> <span class="n">vectorized</span> <span class="n">version</span><span class="o">.</span>
<span class="o">&gt;&gt;</span> <span class="n">As</span> <span class="n">before</span> <span class="k">with</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span> <span class="nb">float</span><span class="p">,</span> <span class="n">vectorized</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="n">gives</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;</span> <span class="n">Now</span> <span class="n">we</span> <span class="k">try</span> <span class="k">with</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span>  <span class="mi">0</span>  <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="n">Calling</span> <span class="n">vectorized</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="n">gives</span> <span class="n">the</span> <span class="n">correct</span> <span class="n">result</span><span class="err">!</span>
<span class="o">&gt;&gt;</span> <span class="n">vectorized</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">]</span></code></pre></figure>

<h2 id="the-joblib-library">The Joblib Library</h2>

<p>Finally, we provide a very simple example of how to parallelise for loops in Python. The exact improvement you get of course depends on the number of cores you have, but running on a cluster or a good desktop, you can find improvements of 10-100x with very little effort. To illustrate this we show how to transform a for loop into a parallelised form.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>

<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

<span class="c1"># For loop:
</span><span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]):</span>
    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    
<span class="c1"># Parallelised:
</span><span class="n">result</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">add</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]))</span></code></pre></figure>
:ET